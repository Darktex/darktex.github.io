---
layout: post
category : blog
tags : [Machine Learning, Neural Nets, RNN, LSTM, Torch, JavaScript]
title: "Deploying a model trained with GPU in Torch into JavaScript, for everyone to use"
comments: on
languages: en
---

It's a great time to be into machine learning and artificial intelligence. Since deep learning took the world by storm in the last few years, there are new and exciting papers coming out almost every day. The speed at which the state of the art evolves is startling and indeed it is very hard to keep up! I've had this problem myself and I decided to spend some time on a fun project to better understand these sequence models everyone is so hyped about. [LSTMs (Long-short term memories)](https://en.wikipedia.org/wiki/Long_short-term_memory) have been around for quite some time (they were introduced in 1998, which is AGES ago for this field!), but it's only recently that the community has managed to train them on huge data and at scale (they had a variety of problems about which you can read [here](http://cs224d.stanford.edu/notebooks/vanishing_grad_example.html), for example).

As the field's boom is still quite recent, there has been only little effort in enabling users to take advantage of these techniques without specific equipment and/or lengthy installations of frameworks. It shouldn't be like this and I believe there hasn't been enough effort in abstracting the complexity away from the end user yet. That being said, there is some previous work in this direction: [Andrej Karpathy](http://cs.stanford.edu/people/karpathy/) shared a suite of JavaScript modules that can run in your browser. They are completely cross-platform (Windows, Mac, Linux, but also Android and iOS) and they can be used for a variety of tasks. He divided his code into three libraries, that cover three different applications: [ConvNetJS](http://cs.stanford.edu/people/karpathy/convnetjs/), [REINFORCEjs](http://cs.stanford.edu/people/karpathy/reinforcejs/) and [RecurrentJS](http://cs.stanford.edu/people/karpathy/recurrentjs/).

However, while these tools are great for some simple applications, they take a very long time to train a good model - we are talking days. The reason why they are so slow is because they use the CPU to do all the calculations. One of the biggest advances in the field and - in my opinion - the biggest enabler for its recent success has been the discovery that graphic cards can be used instead of a CPU for these task, and they work __a lot__ faster[^nvidia]. This is an amazing success in itself: a good GPU costs 300$ and that is already enough to train pretty good models! However, what was missing was the possibility to train a model on a GPU and deploy it so that everyone could use it, without buying or installing anything[^deployment].

The code that I'm releasing today does just that and acts as a bridge between two projects Karpathy made: char-rnn and RecurrentJS. I'm releasing all the code on [my GitHub](https://github.com/Darktex/char-rnn), as well as [a demo](http://testuggine.ninja/Trumpinator/) that I'm confident most will find amusing.

It runs quite fast (almost instantaneously on the few machines I have tried it on) despite running a decently sized model (the model has two stacked LSTMs, each with 300 units).



[^nvidia]: nVidia [claims](http://www.nvidia.com/object/machine-learning.html) GPUs are usually between 10 and 100 times faster than a CPU.
[^deployment]: Running a pre-trained model takes a fraction of the time required to train it, so CPUs can do just fine on this task.
