---
layout: post
category : notes
title: Theory of generalization
tags : [machine learning, caltech course, mooc]
comments: on
languages: en
---

These notes are written in English and refer to the fantastic Caltech online course you can find here: <http://work.caltech.edu/telecourse.html>. It is also worth noting you can find it on iTunes U, and if you have an iPad this makes a fantastic combo :-) The book is here: <http://www.amazon.com/gp/product/1600490069>. I make ample use of Yaser's material, including linking the relevant lecture PDF in each note and using his pictures (this is much faster than drawing stuff myself). Please note this is just for personal use and I give ALL the due credit to him!

A disclaimer on my notes in general: they are meant for my personal use and, although I'd love to know they helped somebody else, they are not written with clarity for third parties in mind. However, if you do use them and you would like to point out any errors, please write me an email!

#Theory of generalization

RELEVANT SLIDES: [Lecture 5](/assets/CaltechML/lecture5.pdf)

When we discussed the [feasibility of learning](/notes/feasibility-of-learning/), what we really talked about was __generalization__ (This is also the conclusion from [Lecture 3](/notes/learning-and-errors/)). 

![4-1](/images/notes/4-1.png)





